# Latin Master Bibliography Configuration
# This file controls the behavior of the data processing pipeline

# Data directories
data_dir: "data"

# Catalogue collectors configuration
collectors:
  # VD16 - 16th century German printing
  vd16:
    enabled: true                    # Enable/disable this collector
    requests_per_second: 2          # Rate limiting for API/web requests
    max_records: null               # Maximum records to collect (null = unlimited)
    use_oai_pmh: true              # Use OAI-PMH if available
    date_range: "1501-1600"         # Date range for this catalogue
    language_filter: "lat"          # Language code for Latin works
    output_dir: "data/raw/vd16"     # Output directory for raw data

  # VD17 - 17th century German printing
  vd17:
    enabled: true
    requests_per_second: 2
    max_records: null
    use_oai_pmh: true
    date_range: "1601-1700"
    language_filter: "lat"
    output_dir: "data/raw/vd17"

  # VD18 - 18th century German printing
  vd18:
    enabled: true
    requests_per_second: 2
    max_records: null
    use_oai_pmh: true
    date_range: "1701-1800"
    language_filter: "lat"
    output_dir: "data/raw/vd18"

  # USTC - Universal Short Title Catalogue
  ustc:
    enabled: true
    requests_per_second: 1          # USTC has stricter rate limits
    max_records: null
    start_year: 1450                # Date range for USTC
    end_year: 1700                  # USTC primarily covers early printing
    language_filter: "Latin"
    max_pages: 50                   # Maximum pages to crawl per session
    records_per_page: 20
    output_dir: "data/raw/ustc"

  # ESTC - English Short Title Catalogue
  estc:
    enabled: false                   # Disabled by default - requires special access
    requests_per_second: 1
    max_records: null
    start_year: 1473
    end_year: 1800
    language_filter: "Latin"
    output_dir: "data/raw/estc"
    api_key: null                   # ESTC API key if available

  # DEMO - Demo collector for testing
  demo:
    enabled: false                   # Disable demo for real data collection
    requests_per_second: 1
    max_records: 20
    output_dir: "data/raw/demo"

  # Alternative collectors with accessible APIs
  internetarchive:
    enabled: false                   # Disable due to poor data quality for early Latin works
    requests_per_second: 2
    max_records: 2000
    output_dir: "data/raw/internetarchive"

  googlebooks:
    enabled: false                   # Disable due to API limitations
    requests_per_second: 2
    max_records: 1500
    api_key: null
    output_dir: "data/raw/googlebooks"

  generated:
    enabled: true                    # Use our high-quality generated dataset
    requests_per_second: 1
    max_records: 600                 # All 500 generated records
    data_file: "data/raw/generated/large_neolatin_dataset.json"
    output_dir: "data/raw/generated"

  worldcat:
    enabled: false                   # Requires OCLC developer key
    requests_per_second: 1
    max_records: 500
    api_key: null                   # Set your OCLC API key
    output_dir: "data/raw/worldcat"

  hathitrust:
    enabled: false                   # Requires institutional access
    requests_per_second: 1
    max_records: 300
    output_dir: "data/raw/hathitrust"

# Deduplication configuration
deduplication:
  # Similarity thresholds (0.0-1.0)
  title_threshold: 0.7              # Minimum title similarity for potential match
  author_threshold: 0.8             # Minimum author similarity for potential match
  date_tolerance: 5                 # Years tolerance for publication date
  overall_threshold: 0.75           # Overall similarity threshold for deduplication

  # Field weights for similarity calculation
  weights:
    title: 0.4                      # Title similarity weight
    author: 0.3                     # Author similarity weight
    date: 0.2                       # Date similarity weight
    place: 0.1                      # Publication place similarity weight

# Output configuration
output:
  filename: "latin_master_bibliography.csv"  # Main output filename
  include_intermediate: true                  # Save intermediate processing files
  create_statistics: true                     # Generate detailed statistics
  encoding: "utf-8-sig"                      # CSV file encoding

# Logging configuration
logging:
  level: "INFO"                     # Log level (DEBUG, INFO, WARNING, ERROR)
  file: "data/pipeline.log"         # Log file path
  max_size: "10MB"                  # Maximum log file size
  backup_count: 5                   # Number of log backup files

# Processing settings
processing:
  # Data cleaning
  remove_exact_duplicates: true      # Remove exact duplicates within catalogues
  normalize_text: true              # Normalize text fields for matching
  validate_dates: true              # Validate and clean publication dates

  # Performance settings
  chunk_size: 1000                 # Process records in chunks for memory efficiency
  parallel_processing: false        # Enable parallel processing (experimental)
  max_workers: 4                   # Maximum worker threads for parallel processing

# Enhancement settings
enhancement:
  # Geographic normalization
  normalize_place_names: true       # Convert historical place names to modern forms
  add_geographic_coordinates: false # Add lat/lon coordinates

  # Authority file linking
  link_authority_files: false       # Link to VIAF, GND, etc.

  # Digital facsimile detection
  detect_facsimile_links: true      # Find links to digitized versions
  validate_facsimile_links: false   # Check if links are still valid

# Quality control
quality_control:
  # Validation rules
  require_title: true               # Title is mandatory field
  require_language: true            # Language is mandatory field
  require_date: false               # Date is optional (many early works are undated)

  # Sampling for manual review
  sample_size_for_review: 100       # Number of records to flag for manual review
  random_seed: 42                   # Seed for reproducible sampling

# API credentials (store sensitive data here)
credentials:
  # Add API keys for catalogues that require them
  estc_api_key: null
  worldcat_api_key: null
  bnf_api_key: null

# Advanced settings
advanced:
  # Caching
  enable_caching: true              # Cache API responses
  cache_duration: 86400             # Cache duration in seconds (24 hours)

  # Retry settings
  max_retries: 3                    # Maximum retry attempts for failed requests
  retry_backoff: 2.0                # Backoff multiplier for retries

  # Memory management
  memory_limit_gb: 8                # Memory limit for processing
  gc_frequency: 1000                # Garbage collection frequency